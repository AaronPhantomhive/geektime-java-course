# 多线程

多线程（multithreading）是指从软件或者硬件上实现多个线程并发执行的技术。具有多线程能力
的计算机因有硬件支持而能够在同一时间执行多于一个线程，进而提升整体处理性能。

并发编程：编写多线程代码，解决多线程带来的问题

## 线程和进程

### 概念

- 进程：是指内存中运行的一个应用程序，每个进程都有自己独立的内存空间；进程也是程序的一次执行过程，是系统运行程序的基本单位；系统运行一个程序即是一个进程从创建、运行到消亡的过程。
- 线程：是进程中的一个执行单元，负责当前进程中任务的执行。一个进程在其执行过程中，会产生很多个线程。

**进程与线程区别**

进程：有独立内存空间，每个进程中的数据空间都是独立的。

线程：多线程之间堆空间与方法区是共享的，但每个线程的栈空间、程序计数器是独立的，线程消
耗的资源比进程小的多。

### 并发与并行

**并发（Concurrent）**：同一时间段，多个任务都在执行 ，单位时间内不⼀定同时执行。

**并行（Parallel）**：单位时间内，多个任务同时执行，单位时间内一定是同时执行。并行上限取决于CPU核数（CPU时间片内50ms）

**※ 并发编程可能导致并行，但是并发编程并不要求是并行的。并发是一种能力，而并行是一种手段。**

### 上下文切换

现在计算机一般都是多核CPU，且OS都能够同时支持远大于CPU内核数的线程运行。那么，OS如何分配CPU资源与调度线程呢？

一个CPU内核，同一时刻只能被一个线程使用。为了提升CPU利用率，CPU采用了时间片算法将CPU时间片轮流分配给多个线程，每个线程分配了一个时间片（几十毫秒/线程），线程在时间片内，使用CPU执行任务。当时间片用完后，线程会被挂起，然后把 CPU 让给其它线程。

- CPU切换前会把当前任务状态保存下来，用于下次切换回任务时再次加载。
- 任务状态的保存及再加载的过程就叫做上下文切换。

**任务状态信息保存**

- 程序计数器：用来存储CPU正在执行的指令的位置，和即将执行的下一条指令的位置。
- 他们都是CPU在运行任何任务前，必须依赖的环境，被叫做CPU上下文。

**上下文切换过程**

1. 挂起当前任务任务，将这个任务在 CPU 中的状态（上下文）存储于内存中的某处。
2. 恢复一个任务，在内存中检索下一个任务的上下文并将在 CPU 的寄存器中恢复。
3. 跳转到程序计数器所指定的位置（即跳转到任务被中断时的代码行）

**线程上下文切换会有什么问题**

过多的线程并行执行会导致CPU资源的争抢，产生频繁的上下文切换，常常表现为高并发执行时，RT延长。因此，合理控制上下文切换次数，可以提高多线程应用的运行效率。（也就是说线程并不是越多越好，要合理的控制线程的数量。）

直接消耗：指的是CPU寄存器需要保存和加载，系统调度器的代码需要执行

间接消耗：指的是多核的cache之间得共享数据，间接消耗对于程序的影响要看线程工作区操作数据的大小

**hw题目 01- 请你说一说什么是线程和进程？**

- 区别

  ```
  进程是资源分配的最小单位，是系统运行程序的基本单位。每个进程都有自己的独立地址内存空间。
  线程是程序执行的最小单位，是cpu调度和分配的基本单位。线程之间的堆空间和方法区共享，栈空间和程序计数器是独立的。
  ```

- 关系

  ```
  一个进程可以包含多个线程，且至少有一个线程，但一个线程只能属于一个进程。
  ```

- 线程的上下文切换是什么？

  ```
  线程的上下文切换指的是在cpu中切换线程执行的过程。
  一个cpu在同一时刻只能被一个线程使用，为了提高效率cpu采用时间片算法将cpu时间片轮流分配给多个线程。
  当一个时间片用完或被阻塞时，cpu会切换线程，把当前线程的执行位置挂起，记录在程序计数器里，用于下次执行时准确查找。然后选择另一个就绪的线程来运行。
  而这个记录与加载的过程，就叫上下文切换。
  ```

- 线程的并发与并行有啥区别？

  ```
  并发是指多个线程在同一时间段内交替执行，但在某一时刻只有一个线程在运行。
  并行是指多个线程在同一时刻同时执行，是真正的多任务处理。并行上限取决于cpu核数。
  ```



### 线程状态：一个线程的一生

Thread源码：Java的线程有六种状态。

```java
public enum State {
	NEW,
	RUNNABLE,
	BLOCKED,
	WAITING,
	TIMED_WAITING,
	TERMINATED;
}
```

NEW(新建) ：线程刚被创建，但是并未启动

RUNNABLE(可运行)：线程可以在Java虚拟机中运行的状态，可能正在运行自己代码，也可能没有，这取决于操作系统处理器

BLOCKED(锁阻塞)：当一个线程试图获取一个对象锁，而该对象锁被其他的线程持有，则该线程进入Blocked状态；当该线程持有锁时，该线程将变成Runnable状态

WAITING(无限等待)：一个线程在等待另一个线程执行一个（唤醒）动作时，该线程进入Waiting状态。进入这个状态后是不能自动唤醒的，必须等待另一个线程调用notify或者notifyAll方法才能够唤醒

TIMED_WAITING(计时等待)：同waiting状态，有几个方法有超时参数，调用他们将进入Timed Waiting状态。这一状态将一直保持到超时期满或者接收到唤醒通知。带有超时参数的常用方法有Thread.sleep 、Object.wait

TERMINATED(被终止)：因为run方法正常退出而死亡，或者因为没有捕获的异常终止了run方法而死亡

![线程状态图](.\note\线程状态图.png)

常用属性：

- 线程名称
- 线程ID：ThreadID = tid
- 线程优先级：Priority

常用方法：

- 线程让步：yield()
- 让线程休眠的方法：sleep()
- 等待线程执行终止的方法： join()
- 线程中断interrupt()
- 等待与通知系列函数wait()、notify()、notifyAll()

wait()与sleep()区别：

- 主要区别：sleep()方法没有释放锁，而wait()方法释放了锁
- 两者都可以暂停线程的执行
- wait()通常用于线程间的交互/通信，sleep()通常用于暂停线程执行
- wait()方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象的notify或notifyAll。
- sleep()方法执行完成后，线程会自动苏醒。或者可以使用wait(long)超时后，线程也会自动苏醒

## 线程安全问题

**hw题目 02：使用了多线程会带来什么问题呢？**

- 能不能详细说说线程安全问题？

  ```
  多个线程同时执行时会访问共享变量，相互之间竞争和冲突，或同时运行一行代码，导致程序出现不稳定和不可预测的行为。而如果每次执行时的运行结果和单线程运行的结果一样，且变量值也与预期相符，则是线程安全的，反之是线程不安全的。
  
  想要解决线程安全问题，可以从线程同步（synchronized）、volatile、锁机制【JUC】（原子类（CAS）、锁（AQS））几方面来解决问题。
  
  线程同步synchronized同步锁机制，是为了保证在同一时刻，被修饰的代码块只会有一个线程在执行。可以保证并发程序的原子性，可见性，有序性的特性。
  
  volatile可以直接修饰变量，保证多线程情况下变量的可见性和有序性，保证所有线程看见的变量的值为一致的。即当一个线程修改了一个volatile变量的值后，其他线程能够立即看到这个变化。缺点为虽然volatile可以保证可见性，但是不能满足原子性。
  
  锁机制【JUC】（原子类（CAS）、锁（AQS））为java.util.concurrent包的缩写，此2包中定义了并发编程中很常见的工具，例如线程池、阻塞队列、同步器、原子类等等。
  其中的Atomic包（java.util.concurrent.atomic包）可以解决volatile直接修饰变量存在原子性的bug。
  原子类是利用CAS（Compare And Swap）算法实现的无锁的线程安全的操作类，可以保证对基本数据类型和引用类型的原子更新。
  CAS的执行函数可以看作CAS(V,E,N)，其中V：要读写的内存地址，E：进行比较的值（预期值），N：拟写入的新值。
  CAS算法是一种乐观锁的思想，当内存地址的V中的值等于预期值E时，将内存地址的V中的值改为N，否则会进行自旋操作，即通过比较内存中的值和预期值如果相同则更新否则重试至相同为止。
  AQS(AbstractQueuedSynchronizer)是互斥锁，可以保证多个线程在临界区串行执行。AQS有独占模式和共享模式，独占模式为同一时刻只有一个线程能够获取同步状态，共享模式为同一时刻有多个线程获取同步状态。
  ```

- 原子性、有序性和可见性能不能深入的谈一下。

  ```
  原子性是指一个操作或者一系列操作要么全部执行成功，要么全部不执行，不能被其他线程干扰或者中断。
  有序性是指程序按照代码的先后顺序执行，可以保证程序的逻辑正确和预期结果正确。当指令重排时会出现无序问题。
  可见性是指当一个线程修改了共享资源的值后，其他线程能够及时地看到这个修改。如果没有可见性，那么可能会出现一个线程修改了变量的值，但是其他线程仍然读取到旧的值，导致逻辑错误。
  ```

### 线程安全

如果有多个线程在同时执行，而多个线程可能会同时运行一行代码。如果程序每次运行结果和单线程运行的结果一样，且其他的变量的值也和预期一样，就是线程安全的，反之则是线程不安全的。

### 原因

线程安全问题都是由全局变量及静态变量【共享】引起的。

- 如果每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的
- 如果有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全问题。

如何解决？

- **线程同步**
- **volatile**
- **锁机制【JUC】**
  - **原子类（CAS）**
  - **锁（AQS）**

### 线程同步

为了保证不出现线程安全问题，Java引入了线程同步机制（synchronized）

1. 同步代码块Synchronized-重量级锁
2. 同步方法Synchronized-重量级锁
3. 锁机制【JUC】

**同步代码块**

```java
public void method() {
    private final Object lock = new Object(); // 锁对象，可以是任意类型数据
    synchronized(lock) {
      // 需要同步操作的代码
    }
}
```

**同步方法**

```java
public synchronized void method() {
    //可能会产生线程安全问题的代码
}
```

**Lock锁**

```java
Lock lock = new ReentrantLock(); // 可重入锁
lock.lock();
// 需要同步操作的代码
lock.unlock();
```

## 多线程并发的三个重要特性

- 原子性：即一个操作或多个操作，要么全部执行，要么就都不执。执行过程中，不能被打断
- 有序性：程序代码按照先后顺序执行
  - 为什么会出现无序问题呢？因为指令重排
- 可见性：当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即得到修改的值
  - 为什么出现不可见性问题呢？可以说是因为Java内存模型【JMM】

## Java内存模型（JMM）

Java为了保证并发编程中可以满足原子性、可见性及有序性，诞生出了一个重要的概念，那就是内存模型，内存模型定义了共享内存系统中多线程程序读写操作行为的规范。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性，它解决了 CPU 多级缓存、处理器优化、指令重排等导致的内存访问问题。

Java实现了JMM规范保证Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范，JMM在Java中的实现屏蔽了各种硬件和操作系统的访问差异。

### 内存模型怎么解决并发问题的？

- 内存模型解决并发问题主要采取两种方式，分别是限制处理器优化，另一种是使用了内存屏障。
- 而对于这两种方式，Java底层其实已经封装好了一些关键字，我们只需要用起来就可以了，不需要关注底层具体如何实现。
- 关于解决并发编程中的原子性问题，Java底层封装了Synchronized的方式，来保证方法和代码块内的操作都是原子性的；
- 而至于可见性问题，Java底层则封装了Volatile的方式，将被修饰的变量在修改后立即同步到主内存中。
- 至于有序性问题，其实也就是我们所说的重排序问题，Volatile关键字也会禁止指令的重排序，而Synchroinzed关键字由于保证了同一时刻只允许一条线程操作，自然也就保证了有序性。
- JMM定义一个共享变量何时写入，何时对另一个线程可见
- 线程之间的共享变量存储在主内存：
  - 主要存储的是Java实例对象，所有线程创建的实例对象都存放在主内存中，不管该实例对象是成员变量还是方法中的本地变量（也称局部变量）。
  - 由于主内存是共享数据区，多条线程对同一个变量访问会出现线程安全问题。
- 每个线程都有一个私有的本地内存，本地内存存储共享变量的副本
  - 主要存储当前方法的所有本地变量，每个线程只能访问自己的本地内存。
  - 线程中的本地变量对其它线程是不可见的，就算是两个线程执行同一段代码，它们也会在自己的本地内存中，创建属于自己线程的本地变量。
- 本地内存是抽象概念涵盖：缓存，写缓冲区，寄存器等

### JMM线程操作内存的基本规则

- 关于线程与主内存：线程对共享变量的所有操作都必须在自己的本地内存中进行，不能直接从主内存中读写
- 关于线程间本地内存：不同线程之间无法直接访问其他线程本地内存中的变量，线程间变量值的传递需要经过主内存

## 内存可见性

可见性是一个线程对共享变量值的修改，能够及时的被其他线程看到。

![内存可见性](.\note\内存可见性.png)

## synchronized

一般情况下，我们会把synchronized称为重量级锁。主要原因，是因为JDK1.6之前，synchronized是一个重量级锁相比于JUC的锁显得非常笨重，存在性能问题。JDK1.6及之后，Java对synchronized进行的了一系列优化，性能与JUC的锁不相上下

synchronized保证方法或者代码块在运行时，同一时刻只有一个线程执行代码块，还可以保证共享变量的内存可见性，也可以保证修饰的代码块重排序也不会影响其执行结果。

一句话：synchronized可以保证并发程序的原子性，可见性，有序性

synchronized可以修饰方法和代码块。

- 方法：可修饰静态方法和非静态方法
- 代码块：同步代码块的锁对象可以为当前实例对象、字节码对象（class）、其他实例对象

### 锁优化

偏向锁和轻量级锁

同步锁一共有四种状态，级别从低到高依次是：无锁，偏向锁，轻量级锁，重量级锁。这四种状态会随着竞争激烈情况逐渐升级

#### 偏向锁

偏向锁则是基这样一个想法：只有一个线程访问锁资源（无竞争）的话，偏向锁就会把整个同步措施都消除，并记录当前持有锁资源的线程和锁的类型。

#### 轻量级锁

轻量级锁是基于这样一个想法：只有两个线程交替运行时，如果线程竞争锁失败了，先不立即挂起，而是自旋一会，在等待过程中，可能锁就被释放了，这时该线程就可以重新尝试获取锁，同时记录持有锁资源的线程和锁的类型。

## volatile

### 定义

Java允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。

即

volatile可以保证多线程场景下变量的可见性和有序性。如果某变量用volatile修饰，则可以确保所有线程看到变量的值是一致的。

- 可见性：保证此变量的修改对所有线程的可见性。
- 有序性：禁止指令重排序优化，编译器和处理器在进行指令优化时，不能把在volatile变量操作(读/写)后面的语句放到其前面执行，也不能将volatile变量操作前面的语句放在其后执行。遵循了JMM的happens-before规则

### 内存屏障

volatile实现内存可见性原理：内存屏障（Memory Barrier）

内存屏障（Memory Barrier）是一种CPU指令，用于控制特定条件下的重排序和内存可见性问题。Java编译器也会根据内存屏障的规则禁止重排序

- 写操作时，通过在写操作指令后加入一条store屏障指令，让本地内存中变量的值能够刷新到主内存中
- 读操作时，通过在读操作前加入一条load屏障指令，及时读取到变量在主内存的值

### 缺点

虽然volatile可以保证可见性，但是不能满足原子性

## JUC

java.util.concurrent（简称JUC）包

### 原子类与CAS

原子类是利用CAS（Compare And Swap）算法实现的无锁的线程安全的操作类，可以保证对基本数据类型和引用类型的原子更新。CAS的执行函数可以看作CAS(V,E,N)

其中:

V：要读写的内存地址

E：进行比较的值（预期值）

N：拟写入的新值

CAS算法是一种乐观锁的思想，当内存地址的V中的值等于预期值E时，将内存地址的V中的值改为N，否则会进行自旋操作，即通过比较内存中的值和预期值如果相同则更新否则重试至相同为止。

#### CAS缺陷

- 循环时间太长、只能保证一个共享变量原子操作、ABA问题。
- 循环时间太长：如果CAS一直不成功呢？如果自旋CAS长时间地不成功，则会给CPU带来非常大的开销。
  - 原子类AtomicInteger#getAndIncrement()的方法
- 只能保证一个共享变量原子操作：看了CAS的实现就知道这只能针对一个共享变量，如果是多个共享变量就只能使用锁了。
- ABA问题：CAS需要检查操作值有没有发生改变，如果没有发生改变则更新。但是存在这样一种情况：如果一个值原来是A，变成了B，然后又变成了A，那么在CAS检查的时候会发现没有改变，但是实质上它已经发生了改变，这就是所谓的ABA问题。对于ABA问题其解决方案是加上版本号，即在每个变量绑定一个版本号，每次改变时加1，即A —> B —> A，变成1A —> 2B —> 3A。

### Atomic包

java.util.concurrent.atomic包

Atomic里的类主要包括：

- 基本类型-使用原子的方式更新基本类型
  - AtomicInteger：整形原子类
  - AtomicLong：长整型原子类
  - AtomicBoolean ：布尔型原子类
- 引用类型
  - AtomicReference：引用类型原子类
  - AtomicStampedReference：原子更新引用类型里的字段原子类
  - AtomicMarkableReference ：原子更新带有标记位的引用类型
- 数组类型-使用原子的方式更新数组里的某个元素
  - AtomicIntegerArray：整形数组原子类
  - AtomicLongArray：长整形数组原子类
  - AtomicReferenceArray ：引用类型数组原子类
- 对象的属性修改类型
  - AtomicIntegerFieldUpdater:原子更新整形字段的更新器
  - AtomicLongFieldUpdater：原子更新长整形字段的更新器
  - AtomicReferenceFieldUpdater ：原子更新引用类形字段的更新器
- JDK1.8新增类
  - DoubleAdder：双浮点型原子类
  - LongAdder：长整型原子类
  - DoubleAccumulator：类似DoubleAdder，但要更加灵活(要传入一个函数式接口)
  - LongAccumulator：类似LongAdder，但要更加灵活(要传入一个函数式接口)

#### AtomicInteger主要API如下

```java
get() //直接返回值
getAndAdd(int) //增加指定的数据，返回变化前的数据
getAndDecrement() //减少1，返回减少前的数据
getAndIncrement() //增加1，返回增加前的数据
getAndSet(int) //设置指定的数据，返回设置前的数据

addAndGet(int) //增加指定的数据后返回增加后的数据
decrementAndGet() //减少1，返回减少后的值
incrementAndGet() //增加1，返回增加后的值
lazySet(int) //仅仅当get时才会set

compareAndSet(int, int)//尝试新增后对比，若增加成功则返回true否则返回false
```

### Lock锁与AQS

#### 锁的分类：按上锁方式划分

- 隐式锁：synchronized
  - synchronized为Java的关键字，是Java提供的同步机制，当它用来修饰一个方法或一个代码块时，能够保证在同一时刻最多只能有一个线程执行该代码。当使用synchronized修饰代码时，并不需要显式的执行加锁和解锁过程，所以它也被称之为隐式锁
- 显式锁：JUC包中提供的锁
  - JUC中提供的锁都提供了常用的锁操作，加锁和解锁的方法都是显式的，我们称他们为显式锁。

#### 锁的分类：按特性划分

- 乐观锁/悲观锁：按照线程在使用共享资源时，要不要锁住同步资源，划分为：乐观锁和悲观锁。
  - 悲观锁：比较悲观，总是假设最坏的情况，对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。
    - 实现：JUC的锁、Synchronized
  - 乐观锁：比较乐观，总是假设最好的情况，对于同一个数据的并发操作，乐观锁认为自己在使用数据时不会有别的线程修改数据，所以在获取数据的时候不会添加锁。只有在更新数据的时候才会去判断有没有别的线程更新了这个数据，如果这个数据没有被更新，当前线程将自己修改的数据成功写入；如果数据已经被其他线程更新，则会根据不同的情况执行不同的操作（例如：报错或自动重试）
    - 实现：CAS算法，关系型数据库的版本号机制

- 可重入锁/不可重入锁：按照同一个线程是否可以重复获取同一把锁，划分为：可重入锁和不可重入锁。
  - 重入锁：一个线程可以重复获取同一把锁，不会因为之前已经获取了该锁未释放而被阻塞。在获得一个锁之后未释放锁之前，再次获得同一把锁时，只会增加获得锁的次数，当释放锁时，会同时减少锁定次数。可重入锁的一个优点是可一定程度避免死锁。
    - 实现：ReentrantLock、synchronized
  - 非重入锁：不可重入锁，与可重入锁相反，同一线程获得锁之后不可再次获取，重复获取会发生死锁。

- 公平锁/非公平锁：按照多个线程竞争同一锁时需不需要排队，能不能插队，划分为公平锁和非公平锁。
  - 公平锁：多个线程按照申请锁的顺序来获得锁
    - 实现：new ReentrantLock(true)
- 非公平锁：多个线程获取锁的顺序并不是按照申请锁的顺序，允许“插队”，有可能后申请的线程比先申请的线程优先获取锁
  - 实现：new ReentrantLock(false)，synchronized

- 独享锁/共享锁：按照多个线程能不能同时共享同一个锁，锁被划分为独享锁和排他锁。
  - 独享锁（写锁）：独享锁也叫排他锁，是指同一个锁同时只能被一个线程所持有。如果线程A对获得了锁S后，则其他线程只能阻塞等待线程A释放锁S后，才能获得锁S。
    - 实现：synchronized，ReentrantLock
  - 共享锁（读锁）：同一个锁可被多个线程同时持有。如果线程A对获得了共享锁S后，则其他线程无需等待可以获得共享锁S。
    - 实现：ReentrantReadWriteLock的读锁。
  - 在ReentrantReadWriteLock维护了一对关联锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。ReadLock(读锁)用于读操作的，WriteLock(写锁)用于写操作，读锁是共享锁，写锁是独享锁，读锁可保证在读多写少的场景中，提高并发读的性能，增加程序的吞吐量。

#### 锁的分类：其他常见的锁

- 自旋锁：获取锁失败时，线程不会阻塞而是循环尝试获得锁，直至获得锁成功。
  - 实现：CAS，举例：AtomicInteger#getAndIncrement()
- 分段锁：在并发程序中，使用独占锁时保护共享资源的时候，基本上是采用串行方式，每次只能有一个线程能访问它。串行操作是会降低可伸缩性，在某些情况下我们可以将锁按照某种机制分解为一组独立对象上的锁，这成为分段锁。
  - 说的简单一点：容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率。
- ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。
  - 实现：ConcurrentHashMap
- 无锁/偏向锁/轻量级锁/重量级锁：
  - 这四个锁是synchronized独有的四种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。它们是JVM为了提高synchronized锁的获取与释放效率而做的优化。四种状态会随着竞争的情况逐渐升级，而且是不可逆的过程，即不可降级。


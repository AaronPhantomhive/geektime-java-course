# MySQL架构

## MySQL架构图

![MySQL架构图](.\note\MySQL架构图.png)

- Connectors连接器：负责跟客户端建立连接
- Management Serveices & Utilities系统管理和控制工具
- Connection Pool连接池：管理用户连接，监听并接收连接的请求，转发所有连接的请求到线程管理模块
- SQL Interface SQL接口：接受用户的SQL命令，并且返回SQL执行结果
- Parser解析器：SQL传递到解析器的时候会被解析器验证和解析
- Optimizer查询优化器：SQL语句在查询之前会使用查询优化器对查询进行优化，explain语句查看的SQL语句执行计划，就是由此优化器生成
- Cache和Buffer查询缓存：在MySQL5.7中包含缓存组件。在MySQL8中移除了
- Pluggable Storage Engines存储引擎：存储引擎就是存取数据、建立与更新索引、查询数据等技术的实现方法

## 一条SQL语句的完整执行流程

作业题目：一条 SQL 语句在 MySQL 中是如何执行的？

```
第一步：连接器连接到数据库
客户端通过连接器建立连接，进行权限验证。
如果有权限，就可以继续执行后面的操作。
连接完成后，如果没有后续动作，则连接处于空闲状态。
客户端如果太长时间（由参数 wait_timeout 控制，默认值是 8 小时）没动静，连接器就会自动断开。

第二步：查询缓存
MySQL 会先检查查询缓存中是否有相同的 SQL 语句和结果，如果有，会被直接返回给客户端，否则就进入下一步。
执行完成后，执行结果会被存入查询缓存中。
MySQL 8.0 及以上版本已经移除了查询缓存功能。
缓存功能缺点：
成本高：查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。
命中率不高：对于更新压力大的数据库来说，查询缓存的命中率会非常低。

第三步：分析器分析SQL语句
客户端程序发送过来的请求，实际上是字符串。
MySQL 会对 SQL 语句进行词法分析和语法分析，将 SQL 语句解析成 MySQL 能理解的结构化表示。
编译的过程，有词法解析、语法分析、预处理器。
词法分析为把一个完整的 SQL 语句分割成一个个的字符串。
语法分析器根据词法分析的结果做语法检查，判断输入的SQL语句是否满足MySQL的语法。
预处理器则会进一步去检查解析树是否合法，比如表名是否存在，语句中表的列是否存在，是否有表操作权限等等。
预处理之后会得到一个新的解析树，然后调用对应执行模块

第四步：优化器优化SQL语句
MySQL 会对 SQL 语句进行优化，根据解析树生成不同的执行计划。
比如选择合适的索引，确定表的连接顺序等，然后选择最优的执行计划。

第五步：执行器执行SQL语句
开始执行之前会判断一下有没有执行查询的权限，如果没有，就会返回没有权限的错误。
如果有权限，就使用指定的存储引擎打开表开始查询。
执行器会根据表的引擎定义，去使用这个引擎提供的查询接口，对数据进行存取操作，并返回结果给客户端。
```

### Sql语句执行流程

分析SQL语句如下：

```sql
select c_id,first_name,last_name from customer where c_id=14;
```

1. Server层
  - 包括：连接器、查询缓存、分析器、优化器、执行器等
  - 涵盖 MySQL的大多数核心服务功能
  - 所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现
    - 比如：存储过程、触发器、视图等
2. 存储引擎层：
  - 负责数据的存储和提取
  - 可插拔式存储引擎：InnoDB、MyISAM、Memory 等
  - 最常用存储引擎是InnoDB
  - 从MySQL 5.5版本开始，默认存储引擎是InnoDB

![一条SQL语句的完整执行流程](.\note\一条SQL语句的完整执行流程.png)

### 第一步：连接到数据库

首先会连接到这个数据库上，这时候接待你的就是连接器。

```shell
-- 连接命令
mysql -h127.0.0.1 -P3306 -uroot -p
```

连接完成后，如果你没有后续的动作，这个连接就处于空闲状态。客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的默认值是 8 小时。

```sql
mysql> show processlist;
# 其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。
```

### 第二步：查缓存

MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句hash之后的值，value是查询的结果。

- 如果你的查询语句在缓存中，会被直接返回给客户端。
- 如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。

如果查询命中缓存，MySQL 不需要执行后面的复杂操作就可以直接返回结果，效率会很高！但是不建议使用MySQL的内置缓存功能

#### **查询缓存**

```sql
# 1）查看是否开启缓存
mysql> show variables like 'query_cache_type';
# 2）查看缓存的命中次数：
mysql> show status like 'qcache_hits';
# 3）开启缓存
在/etc/my.cnf文件中修改“query_cache_type”参数
值为`0或OFF`会禁止使用缓存。
值为`1或ON`将启用缓存，但以`SELECT SQL_NO_CACHE`开头的语句除外。
值为`2或DEMAND`时，只缓存以`SELECT SQL_CACHE`开头的语句。
```

修改配置文件 my.cnf ，在文件中增加如下内容开启缓存：

```shell
query_cache_type=1
```

查询SQL：

```sql
mysql> select * from city where city_id = 1;
```

#### **清空查询缓存**

可以使用下面三个SQL来清理查询缓存：

```sql
FLUSH QUERY CACHE; # 清理查询缓存内存碎片。
RESET QUERY CACHE; # 从查询缓存中移出所有查询。
FLUSH TABLES; # 关闭所有打开的表，同时该操作将会清空查询缓存中的内容。
```

#### **为什么不建议使用MySQL的查询缓存？**

因为查询缓存往往弊大于利

- 成本高：查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。
- 命中率不高：对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。
- 功能并不如专业的缓存工具更好：redis、memcache、ehcache...

```sql
mysql> select sql_cache * from city where city_id = 1;
```

### 第三步：分析SQL语句

如果查询缓存没有命中，接下来就需要进入正式的查询阶段了。客户端程序发送过来的请求，实际上只是一个字符串而已，所以MySQL服务器程序首先需要对这个字符串做分析，判断请求的语法是否正确，然后从字符串中将要查询的表、列和各种查询条件都提取出来，本质上是对一个SQL语句编译的过程，涉及**词法解析、语法分析、预处理器**等

- 词法分析：词法分析就是把一个完整的 SQL 语句分割成一个个的字符串
- 语法分析：语法分析器根据词法分析的结果做语法检查，判断你输入的SQL 语句是否满足 MySQL语法。
- 预处理器：预处理器则会进一步去检查解析树是否合法，比如表名是否存在，语句中表的列是否存在等等，在这一步MySQL会检验用户是否有表的操作权限。

#### 词法分析

比如：这条简单的SQL语句，会被分割成10个字符串

```sql
# 分隔前
select c_id,first_name,last_name from customer where c_id=14;
# 分隔后
select，c_id,first_name,last_name，from，customer，where，c_id，=，14
```

MySQL 同时需要识别出这个SQL语句中的字符串分别是什么，代表什么。

- 把"select"这个关键字识别出来，这是一个查询语句
- 把“customer”识别成“表名 customer”
- 把“c_id识别成“列 c_id”

#### 语法分析

如果语法正确就会根据 MySQL语法规则与SQL 语句生成一个数据结构，这个数据结构我们把它叫做解析树

```sql
mysql> select c_id,first_name,last_name form customer where c_id=14;

[Err] 1064 - You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'customer where c_id=14' at line 1
# 错误原因：from 写为 form
```

![解析数](.\note\解析数.png)

#### 预处理器

预处理器则会进一步去检查解析树是否合法，比如表名是否存在，语句中表的列是否存在等等，在这一步MySQL会检验用户是否有表的操作权限。

预处理之后会得到一个新的解析树，然后调用对应执行模块

### 第四步：优化SQL语句

优化器顾名思义就是对查询进行优化。作用是根据解析树生成不同的执行计划，然后选择最优的执行计划。

MySQL 里面使用的是基于成本模型的优化器，哪种执行计划Explain执行时成本最小就用哪种。而且它是io_cost和cpu_cost的开销总和，它通常也是我们评价一个查询的执行效率的一个常用指标。

查看上次查询成本开销，默认值是0

```sql
show status like 'Last_query_cost';
```

### 第五步：执行SQL语句

- 判断执行权限
  - 开始执行的时候，要先判断一下你对这个表customer有没有执行查询的权限，如果没有，就会返回没有权限的错误。
- 调用存储引擎接口查询
  - 如果有权限，就使用指定的存储引擎打开表开始查询。执行器会根据表的引擎定义，去使用这个引擎提供的查询接口提取数据。
  - c_id是主键执行流程：
    - 调用 InnoDB 引擎接口，从主键索引中检索c_id=14的记录。
    - 主键索引等值查询只会查询出一条记录，直接将该记录返回客户端。
    - 至此，这个语句就执行完成了。
  - c_id不是主键执行流程：全表扫描
    - 调用 InnoDB 引擎接口取这个表的第一行，判断c_id 值是不是 14，如果不是则跳过，如果是则将这行缓存在结果集中；
    - 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行
    - 执行器将上述遍历过程中所有满足条件的行组成的结果集返回给客户端。
    - 至此，这个语句就执行完成了。

## MySQL的存储引擎之InnoDB

### 存储引擎种类

![存储引擎种类](.\note\存储引擎种类.png)

InnoDB和MyISAM存储引擎区别

| **比较项**   | **Innodb**                                   | **MyISAM**                                            |
| ------------ | -------------------------------------------- | ----------------------------------------------------- |
| **存储文件** | .frm 表定义文件<br />.ibd 数据文件和索引文件 | .frm 表定义文件<br />.myd 数据文件<br />.myi 索引文件 |
| **锁**       | 表锁、行锁                                   | 表锁                                                  |
| **事务**     | 支持                                         | 不支持                                                |
| **CRUD**     | 读、写                                       | 读多                                                  |
| **索引结构** | B+ Tree                                      | B+ Tree                                               |

### InnoDB架构图

![InnoDB架构图](.\note\InnoDB架构图.png)

### 内存结构

InnoDB 内存结构主要分为如下四个区域：
1. Buffer Pool 缓冲池
2. Change Buffer 修改缓冲
3. Adaptive Hash Index 自适应索引
4. Log Buffer 日志缓冲

#### 缓冲池(Buffer Pool)

缓冲池Buffer Pool 用于加速数据的访问和修改，通过将热点数据缓存在内存的方法，最大限度地减少磁盘 IO，加速热点数据读写。

- 默认大小为128M，Buffer Pool 中数据以页为存储单位，其实现的数据结构是以页为单位的单链表。
- 由于内存的空间限制，Buffer Pool 仅能容纳最热点的数据。
- Buffer Pool 使用LRU算法（Least Recently Used 最近最少使用）淘汰非热点数据页。
- LRU：根据页数据的历史访问来淘汰数据，如果数据最近被访问过，那么将来被访问的几率也更高，优先淘汰最近没有被访问到的数据。
- 对于 Buffer Pool 中数据的查询，InnoDB 直接读取返回。对于 Buffer Pool 中数据的修改，InnoDB 直接在 Buffer Pool 中修改，并将修改写入redo log

#### 修改缓冲(Change Buffer)

Change Buffer（在 MySQL 5.6 之前叫 insert buffer，简称 ibuf ）是 InnoDB 5.5 引入的一种优化策略。

Change Buffer 用于加速非热点数据中二级索引的写入操作。

由于二级索引数据的不连续性，导致修改二级索引时需要进行频繁的磁盘 IO 消耗大量性能，Change Buffer 缓冲对二级索引的修改操作，同时将写操作录入 redo log 中，在缓冲到一定量或系统较空闲时进行 merge 操作将修改写入磁盘中。

Change Buffer 在系统表空间中有相应的持久化区域。

Change Buffer 大小默认占 Buffer Pool 的 25%，最大50%，在引擎启动时便初始化完成。

其物理结构为一棵名为 ibuf 的 B Tree

> 二级索引就是辅助索引，除了聚簇索引之外的所有索引都是二级索引。
>
> 聚簇索引也叫聚集索引，索引组织表，指的是一种数据存储方式，指数据与索引的数据结构存储在一起。
>
> 如 InnoDB 的主键索引中所有叶子节点都存储了对应行的数据。因为数据肯定只是存储在一个地方，所以一个表只能有一个聚集索引。

#### 自适应哈希索引(AHI)

自适应哈希索引（Adaptive Hash Index，AHI）用于实现对于热数据页的一次查询。

是建立在索引之上的索引。

使用聚簇索引进行数据页定位的时候需要根据索引树的高度从根节点走到叶子节点，通常需要3 到 4 次查询才能定位到数据。

InnoDB 根据对索引使用情况的分析和索引字段的分析，通过自调优Self-tuning的方式为索引页建立或者删除哈希索引。

AHI 的大小为 Buffer Pool 的 1/64，在 MySQL 5.7 之后支持分区，以减少对于全局 AHI 锁的竞争，默认分区数为 8。

AHI 所作用的目标是频繁查询的数据页和索引页，而由于数据页是聚簇索引的一部分。

因此 AHI 是建立在索引之上的索引，对于二级索引，若命中AHI，则将直接从 AHI 获取二级索引页的记录指针，再根据主键沿着聚簇索引查找数据。

若聚簇索引查询同样命中 AHI，则直接返回目标数据页的记录指针，此时就可以根据记录指针直接定位数据页。

#### 日志缓冲(Log Buffer)

InnoDB 使用 Log Buffer 来缓冲日志文件的写入操作。内存写入加上日志文件顺序写的特点，使得InnoDB 日志写入性能极高。

对于任何修改操作，都将录入诸如 redo log 与 undo log 这样的日志文件中，因此日志文件的写入操作非常频繁，却又十分零散。

这些文件都存储在磁盘中，因此日志记录将引发大量的磁盘 IO。

Log Buffer将分散的写入操作放在内存中，通过定期批量写入磁盘的方式提高日志写入效率和减少磁盘 IO。

### 脏页落盘

#### 脏页

对于数据库中页的修改操作，则首先修改在缓冲区中的页，缓冲区中的页与磁盘中的页数据不一致，所以称缓冲区中的页为脏页。然后再以一定的频率将脏页刷新到磁盘上。页从缓冲区刷新回磁盘的操作并不是在每次页发生更新时触发，而是通过一种称为CheckPoint的机制刷新回磁盘。

#### 为什么不是每次更新直接写入磁盘

如果每次一个页发生变化就进行落盘，每次落盘一个页，必然伴随着4次IO操作，那么性能开销会非常大。而且这个开销是随着写入操作的增加指数级增长的

如果数据长期在内存中保存，那么数据就存在安全性风险

InnoDB采用了Write Ahead Log（WAL）策略和Force Log at Commit机制实现事务级别下数据的持久性

- Force Log at Commit机制：当事务提交时，所有事务产生的日志都必须刷到磁盘。如果日志刷新成功后，缓冲池中的数据刷新到磁盘前数据库发生了宕机，那么重启时，数据库可以从日志中恢复数据。这样可以保证数据的安全性
- Write Ahead Log（WAL）策略：要求数据的变更写入到磁盘前，首先必须将内存中的日志写入到磁盘；InnoDB 的 WAL（Write Ahead Log）技术的产物就是 redo log，对于写操作，永远都是日志先行，先写入 redo log 确保一致性之后，再对修改数据进行落盘。

#### 怎么确保日志能安全的写入系统

为了确保每次日志都写入到redo日志文件，在每次将redo日志缓冲写入redo日志后，调用一次**fsync**操作，将缓冲文件从文件系统缓存中真正写入磁盘

#### Redo日志落盘

Log Buffer写入磁盘的时机由参数 innodb_flush_log_at_trx_commit 控制，此属性控制每次事务提交时InnoDB的行为。是InnoDB性能调优的一个基础参数，涉及InnoDB的写入性能和数据安全性。默认1，表示事务提交后立即落盘。

```shell
# 查看写入时机参数配置
show VARIABLES like 'innodb_flush_log_at_trx_commit';
```

### CheckPoint检查点机制

#### CheckPoint

Checkpoint要做的事情是将缓冲池中的脏页数据刷到磁盘上。CheckPoint决定了脏页落盘的时机、条件及脏页的选择，不同的CheckPoint做法并不相同。

#### CheckPoint要解决什么问题

**脏页落盘：**避免数据更改直接操作磁盘

**缩短数据库的恢复时间**：当数据库发生宕机时，数据库不需要重做所有的日志，因为Checkpoint之前的页都已经刷新回磁盘。数据库只需对Checkpoint后的redo日志进行恢复，这样就大大缩短了恢复的时间。

**缓冲池不够用时，将脏页刷新到磁盘**：当缓冲池不够用时，根据LRU算法会溢出最近最少使用的页，若此页为脏页，那么需要强制执行Checkpoint，将脏页也就是页的新版本刷回磁盘。

**redo日志不可用时，刷新脏页**：当redo日志出现不可用时，Checkpoint将缓冲池中的页至少刷新到当前redo日志的位置

1. 数据库系统对redo日志的设计都是循环使用的，并不是让其无限增大的。
2. 如果当数据库宕机恢复操作时，不需要redo日志中的部分redo日志，这部分就可以被覆盖重用。
3. InnoDB通过LSN（Log Sequence Number）来标记日志刷新的版本。LSN是8字节的数字，每个页有LSN，redo日志中也有LSN，Checkpoint也有LSN。

### Double Write双写

数据库准备刷新脏页时，将16KB的刷入磁盘，但当写入了8KB时，就宕机了。这种情况被称为写失效（partial page write）。

解决办法：Double Write双写

Doublewrite其实就是写两次，解决写失效问题，需要用到Doublewrite机制，简单来说就是在redo日志前，对需要写入的页的做个副本，当写失效发生时，通过页的副本来还原该页再重做，这就是所谓的double write。写失效后redo日志也是无法进行恢复的，因为redo日志记录的是对页的物理修改。

Double Write分两个部分：

- 内存中的Doublewrite buffer，大小为2MB
- 磁盘上的Doublewrite buffer，大小为2MB，连续的128个页，相当于两个extent

Double write脏页刷新流程：

1. 首先复制：脏页刷新时不直接写磁盘，而是先将脏页复制到内存的Doublewrite buffer
2. 再顺序写：内存的Doublewrite buffer分两次，每次1MB顺序地写入共享表空间的物理磁盘上，会立即调用fsync函数同步OS缓存到磁盘中，顺序写性能好
3. 最后离散写：内存的Doublewrite buffer最后将页写入各自表空间文件中，离散写较顺序写入差一些

Double write崩溃恢复：

如果脏页数据未来得及落盘，系统就奔溃了，直接应用redo日志重新执行脏页落盘。

如果操作系统在将页写入磁盘的过程中发生了崩溃，其恢复过程如下：

1. 首先InnoDB存储引擎从系统表空间中的Double write中找到该页的一个副本
2. 然后将其复制到独立表空间
3. 最后清楚redo日志，完成数据恢复

## 事务

作业题目: 请解释一下你理解的事务是什么？

要点：

事务四大特性 ACID

事务隔离级别

事务会产生的并发问题

事务的安全性、性能与隔离级别的关系

```
事务是指对数据库执行一组逻辑操作，这组操作要么全部成功，要么全部失败。
不会出现部分成功的情况。
本质上为并发编程问题。

事务的四大特性ACID为：
原子性（Atomicity）：事务的最小工作单元。事务中的所有操作，要么全部完成，要么全部不完成，不会停留在中间某个环节。
一致性（Consistency）：事务必须使数据库从一个一致性状态变换到另一个一致性状态，其完整性必须保持一致。即数据的修改必须符合所有的预设规则和约束。
隔离性（Isolation）：多个用户并发使用数据库时，事务的执行不能被其他事务干扰，即一个事务内部的操作和使用的数据对其他并发事务是隔离的。
持久性（Durability）：事务一旦提交，它对数据库中数据的改变就是永久性的，即使系统故障也不会丢失。

事务隔离级别为：
读未提交
（Read Uncommitted）：事务执行过程中可以读取到并发执行的其他事务中未提交的数据，可能会引起脏读、不可重复读、幻读。
读已提交（Read Committed）：事务执行过程中只能读到其他事务已经提交的数据，避免了脏读问题，但可能会出现不可重复读和幻读的问题。
可重复读（Repeatable Read）：当前事务执行开始后，所读取到的数据都是该事务刚开始时所读取的数据和自己事务内修改的数据，无论另一个事务是否提交，避免了不可重复读的问题，但还是有可能出现幻读的问题。
串行化（Serializable）：当前事务执行期间，其他事务不能对数据进行修改，也就是说所有事务都是串行执行的，相当于单线程，避免了所有并发问题，但性能最差。

事务会产生的并发问题有：
脏读：一个事务读到了另一个事务未提交的数据
不可重复读：一个事务读到另一个事务已经update的数据，引发事务中的多次查询结果不一致
幻读/虚读：一个事务读到另一个事务已经insert的数据，导致多次事务中多次查询的结果不一致

事务的安全性、性能与隔离级别的关系：
性能：串行化 < 可重复读 < 读已提交 < 读未提交
安全性：串行化 > 可重复读 > 读已提交 > 读未提交
```

